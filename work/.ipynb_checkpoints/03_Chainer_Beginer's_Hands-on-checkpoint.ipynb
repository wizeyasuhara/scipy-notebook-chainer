{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update (2018/04/20): Chainer v4に合わせ内容を更新しました。\n",
    "\n",
    "**注意：**\n",
    "\n",
    "- 今回はニューラルネットワーク自体が何なのかといった説明は省きます。\n",
    "- この記事はJupyter notebookを使って書かれていますので、コードは上から順番に実行できるようにチェックされています。元のJupyter notebookファイルはこちらにおいてあります。\n",
    "\n",
    "Qiitaだとページ内リンクつきの目次が勝手に作成されるので、全体概要はそちらを眺めて把握してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 学習ループを書いてみよう\n",
    "\n",
    "ここでは、有名な手書き数字のデータセットMNISTを使って、画像を10クラスに分類するネットワークを書いて訓練してみます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. データセットの準備\n",
    "\n",
    "教師あり学習の場合、**データセットは「入力データ」と「それと対になるラベルデータ」を返すオブジェクトである必要があります。**\n",
    "ChainerにはMNISTやCIFAR10/100のようなよく用いられるデータセットに対して、データをダウンロードしてくるところからそのような機能をもったオブジェクトを作るところまで自動的にやってくれる便利なメソッドがあるので、ここではひとまずこれを用いましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chainer.datasets import mnist\n",
    "\n",
    "# データセットがダウンロード済みでなければ、ダウンロードも行う\n",
    "train_val, test = mnist.get_mnist(withlabel=True, ndim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データセットオブジェクト自体は準備ができました。これは、例えば `train_val[i]` などとすると**i番目の `(data, label)` というタプルを返すリスト** と同様のものになっています（**実際ただのPythonリストもChainerのデータセットオブジェクトとして使えます**）。では0番目のデータとラベルを取り出して、表示してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fadf4892518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: 5\n"
     ]
    }
   ],
   "source": [
    "# matplotlibを使ったグラフ描画結果がnotebook内に表示されるようにします。\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# データの例示\n",
    "x, t = train_val[0]  # 0番目の (data, label) を取り出す\n",
    "plt.imshow(x.reshape(28, 28), cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "print('label:', t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Validation用データセットを作る\n",
    "\n",
    "次に、上で作成した`train_val`データセットを、Training用のデータセットとValidation用のデータセットに分割しましょう。これもChainerの便利な関数を使えば簡単にできます。元々60000個のデータが入っている`train`データセット50000個のデータをTraining用に、残りの10000個をValidation用にしてみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chainer.datasets import split_dataset_random\n",
    "\n",
    "train, valid = split_dataset_random(train_val, 50000, seed=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これだけで元々の`train_val`を、ランダムに選んだ50000個の`train`データセットと`valid`データセットに分けることができました。何度も実行する際に異なる分け方になってしまわないよう、第3引数の`seed`を設定しておくことをオススメします。それでは、それぞれのデータセットの中に入っているデータの数を確認してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset size: 50000\n",
      "Validation dataset size: 10000\n"
     ]
    }
   ],
   "source": [
    "print('Training dataset size:', len(train))\n",
    "print('Validation dataset size:', len(valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Iteratorの作成\n",
    "\n",
    "データセットの準備は完了しましたが、このままネットワークの学習に使うのは少し面倒です。なぜなら、ネットワークのパラメータ最適化手法として広く用いられているStochastic Gradient Descent (SGD)という手法では、一般的にいくつかのデータを束ねた**ミニバッチ**と呼ばれる単位でネットワークにデータを渡し、それに対する予測を作って、ラベルと比較するということを行います。そのため、**バッチサイズ分だけデータとラベルを束ねる作業が必要です。**\n",
    "\n",
    "そこで、**データセットから決まった数のデータとラベルを取得し、それらを束ねてミニバッチを作ってくれる機能を持った`Iterator`を使いましょう。**`Iterator`は、先程作ったデータセットオブジェクトを渡して初期化してやったあとは、`next()`メソッドで新しいミニバッチを返してくれます。内部ではデータセットを何周なめたか（`epoch`）などの情報がどうように記録されているおり、学習ループを書いていく際に便利です。\n",
    "\n",
    "データセットオブジェクトからイテレータを作るには、以下のようにします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chainer import iterators\n",
    "\n",
    "batchsize = 128\n",
    "\n",
    "train_iter = iterators.SerialIterator(train, batchsize)\n",
    "valid_iter = iterators.SerialIterator(\n",
    "    valid, batchsize, repeat=False, shuffle=False)\n",
    "test_iter = iterators.SerialIterator(\n",
    "    test, batchsize, repeat=False, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここでは、学習に用いるデータセット用のイテレータ（`train_iter`）と、検証用のデータセット用のイテレータ（`valid_iter`）、および学習したネットワークの評価に用いるテストデータセット用のイテレータ（`test_iter`）の計3つを作成しています。ここで、`batchsize = 128`としているので、作成した3つの`Iterator`は、例えば`train_iter.next()`などとすると128枚の数字画像データを一括りにして返してくれます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE: `SerialIterator`について\n",
    "\n",
    "Chainerがいくつか用意している`Iterator`の一種である`SerialIterator`は、データセットの中のデータを順番に取り出してくる最もシンプルな`Iterator`です。コンストラクタの引数にデータセットオブジェクトと、バッチサイズを取ります。このとき、渡したデータセットオブジェクトから、何周も何周もデータを繰り返し読み出す必要がある場合は`repeat`引数を`True`とし、1周が終わったらそれ以上データを取り出したくない場合はこれを`False`とします。これは、主にvalidation用のデータセットに対して使うフラグです。デフォルトでは、`True`になっています。また、`shuffle`引数に`True`を渡すと、データセットから取り出されてくるデータの順番をエポックごとにランダムに変更します。`SerialIterator`の他にも、マルチプロセスで高速にデータを処理できるようにした`MultiprocessIterator`や`MultithreadIterator`など、複数の`Iterator`が用意されています。詳しくは以下を見てください。\n",
    "\n",
    "- [Chainerで使えるIterator一覧](https://docs.chainer.org/en/stable/reference/iterators.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ネットワークの定義\n",
    "\n",
    "では、学習させるネットワークを定義してみましょう。今回は、全結合層のみからなる多層パーセプトロンを作ってみます。中間層のユニット数は適当に100とし、今回は10クラス分類をしたいので、出力ユニット数は10とします。今回用いるMNISTデータセットは0〜9までの数字のいずれかを意味する10種のラベルを持つためです。では、ネットワークを定義するために必要な`Link`, `Function`, そして`Chain`について、簡単にここで説明を行います。\n",
    "\n",
    "### LinkとFunction\n",
    "\n",
    "Chainerでは、ニューラルネットワークの各層を、`Link`と`Function`に区別します。\n",
    "\n",
    "- **`Link`は、パラメータを持つ関数です。**\n",
    "- **`Function`は、パラメータを持たない関数です。**\n",
    "\n",
    "これらを組み合わせてネットワークを記述します。パラメータを持つ層は、`chainer.links`モジュール以下にたくさん用意されています。パラメータを持たない層は、`chainer.functions`モジュール以下にたくさん用意されています。これらに簡単にアクセスするために、\n",
    "\n",
    "```\n",
    "import chainer.links as L\n",
    "import chainer.functions as F\n",
    "```\n",
    "\n",
    "と別名を与えて、`L.Convolution2D(...)`や`F.relu(...)`のように用いる慣習がありますが、特にこれが決まった書き方というわけではありません。\n",
    "\n",
    "### Chain\n",
    "\n",
    "`Chain`は、**パラメータを持つ層（`Link`）をまとめておくためのクラス**です。パラメータを持つということは、基本的にネットワークの学習の際にそれらを更新していく必要があるということです（更新されないパラメータを持たせることもできます）。Chainerでは、モデルのパラメータの更新は、`Optimizer`という機能が担います。その際、更新すべき全てのパラメータを簡単に発見できるように、`Chain`で一箇所にまとめておきます。そうすると、`Chain.params()`メソッドを使って**更新されるパラメータ一覧が簡単に取得できます。**\n",
    "\n",
    "### Chainを継承してネットワークを定義しよう\n",
    "\n",
    "Chainerでは、ネットワークは`Chain`クラスを継承したクラスとして定義されることが一般的です。その場合、そのクラスのコンストラクタで、`self.init_scope()`で作られる`with`コンテキストを作り、その中でネットワークに登場する`Link`をプロパティとして登録しておきます。こうすると、自動的に`Optimizer`が最適化対象のパラメータを持つ層だな、と捉えてくれます。\n",
    "\n",
    "もう一つ、一般的なのは、ネットワークの前進計算（データを渡して、出力を返す）を、`__call__`メソッドに書いておくという方法です。こうすると、ネットワーククラスをinstantiateして作ったオブジェクトを、関数のようにして使うことができます（例：`output = net(data)`）。\n",
    "\n",
    "### GPUで実行するには\n",
    "\n",
    "`Chain`クラスは`to_gpu`メソッドを持ち、この引数にGPU IDを指定すると、指定したGPU IDのメモリ上にネットワークの全パラメータを転送します。こうしておくと、前進計算も学習の際のパラメータ更新なども全部GPU上で行われるようになります。GPU IDとして-1を使うと、すなわちこれはCPUを意味します。\n",
    "\n",
    "### 同じ結果を保証したい\n",
    "\n",
    "ネットワークを書き始める前に、まずは乱数シードを固定して、本記事とほぼ同様の結果が再現できるようにしておきましょう。（cuDNNが有効になっている環境下でより厳密に計算結果の再現性を保証したい場合は、`chainer.config.cudnn_deterministic`というConfiguringオプションについて知る必要があります。こちらのドキュメントを参照してください：[chainer.config.cudnn_deterministic](https://docs.chainer.org/en/stable/reference/configuration.html?highlight=chainer.config.cudnn_deterministic)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy\n",
    "import chainer\n",
    "\n",
    "def reset_seed(seed=0):\n",
    "    random.seed(seed)\n",
    "    numpy.random.seed(seed)\n",
    "    if chainer.cuda.available:\n",
    "        chainer.cuda.cupy.random.seed(seed)\n",
    "        \n",
    "reset_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ネットワークを表すコード\n",
    "\n",
    "いよいよネットワークを書いてみます！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chainer\n",
    "import chainer.links as L\n",
    "import chainer.functions as F\n",
    "\n",
    "class MLP(chainer.Chain):\n",
    "\n",
    "    def __init__(self, n_mid_units=100, n_out=10):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        # パラメータを持つ層の登録\n",
    "        with self.init_scope():\n",
    "            self.l1 = L.Linear(None, n_mid_units)\n",
    "            self.l2 = L.Linear(n_mid_units, n_mid_units)\n",
    "            self.l3 = L.Linear(n_mid_units, n_out)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        # データを受け取った際のforward計算を書く\n",
    "        h1 = F.relu(self.l1(x))\n",
    "        h2 = F.relu(self.l2(h1))\n",
    "        return self.l3(h2)\n",
    "\n",
    "gpu_id = -1 # GPUの設定をしていないため、取り急ぎ0から-1に変更。  # CPUを用いる場合は、この値を-1にしてください\n",
    "\n",
    "net = MLP()\n",
    "\n",
    "if gpu_id >= 0:\n",
    "    net.to_gpu(gpu_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "できました！疑問点はありませんか？ちなみに、Chainerにはたくさんの学習可能なレイヤやパラメータを持たないレイヤが用意されています。ぜひ一度以下の一覧のページを見てみましょう。\n",
    "\n",
    "- [Chainerで使える関数(`Function`)一覧](https://docs.chainer.org/en/stable/reference/functions.html)\n",
    "- [Chainerで学習できるレイヤ(`Link`)一覧](https://docs.chainer.org/en/stable/reference/links.html)\n",
    "\n",
    "`Link`一覧には、ニューラルネットワークによく用いられる全結合層や畳み込み層、LSTMなどや、ReLUなどの活性化関数などなどだけでなく、有名なネットワーク全体も`Link`として載っています。ResNetや、VGGなどです。また、`Function`一覧には、画像の大きさをresizeしたり、サイン・コサインのような関数を始め、いろいろなネットワークの要素として使える関数が載っています。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE\n",
    "\n",
    "上のネットワーク定義で、`L.Linear`は全結合層を意味しますが、最初のLinear層は第一引数に`None`が渡されています。これは、実行時に、つまり**データがその層に入力された瞬間、必要な数の入力側ユニット数を自動的に計算する**ということを意味します。ネットワークが最初に計算を行う際に、初めて `(n_input)` $\\times$ `n_mid_units` の大きさの行列を作成し、それを学習対象とするパラメータとして保持します。これは後々、畳み込み層を全結合層の前に配置する際などに便利な機能です。\n",
    "\n",
    "様々な`Link`は、それぞれ学習対象となるパラメータを保持しています。それらの値は、NumPyの配列として簡単に取り出して見ることができます。例えば、上のモデル`MLP`は`l1`という名前の全結合層が登録されています。この全結合層は重み行列`W`とバイアス`b`という2つのパラメータを持ちます。これらには外から以下のようにしてアクセスすることができます："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1つ目の全結合相のバイアスパラメータの形は、 (100,)\n",
      "初期化直後のその値は、 [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "print('1つ目の全結合相のバイアスパラメータの形は、', net.l1.b.shape)\n",
    "print('初期化直後のその値は、', net.l1.b.array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "しかしここで、`net.l1.W.array`の中身を同様に表示してみようとすると、`None`が返されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(net.l1.W.array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "なぜでしょうか？我々は`l1`をネットワークに登録するときに、`L.Linear`の第一引数に`None`を渡しましたね。そして、**まだネットワークに一度もデータを入力していません**。そのため、**まだ重み行列`W`は作成されていません。**そのため、まだ`net.l1.W`は具体的な配列を保持していないのです。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 最適化手法の選択\n",
    "\n",
    "では、上で定義したネットワークをMNISTデータセットを使って訓練してみましょう。学習時に用いる最適化の手法としてはいろいろな種類のものが提案されていますが、Chainerは多くの手法を同一のインターフェースで利用できるよう、`Optimizer`という機能でそれらを提供しています。`chainer.optimizers`モジュール以下に色々なものを見つけることができます。一覧はこちらにあります：\n",
    "\n",
    "- [Chainerで使える最適化手法一覧](https://docs.chainer.org/en/stable/reference/optimizers.html)\n",
    "\n",
    "ここでは最もシンプルな勾配降下法の手法である`optimizers.SGD`を用います。`Optimizer`のオブジェクトには、`setup`メソッドを使ってモデル（`Chain`オブジェクト）を渡します。こうすることで`Optimizer`に、何を最適化すればいいか把握させることができます。\n",
    "\n",
    "他にもいろいろな最適化手法が手軽に試せるので、色々と試してみて結果の変化を見てみてください。例えば、下の`chainer.optimizers.SGD`のうち`SGD`の部分を`MomentumSGD`, `RMSprop`,  `Adam`などに変えるだけで、最適化手法の違いがどのような学習曲線（ロスカーブ）の違いを生むかなどを簡単に調べることができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chainer import optimizers\n",
    "\n",
    "optimizer = optimizers.SGD(lr=0.01).setup(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE\n",
    "\n",
    "今回はSGDのコンストラクタの`lr`という引数に $0.01$ を与えました。この値は学習率として知られ、モデルをうまく訓練して良いパフォーマンスを発揮させるために調整する必要がある重要な**ハイパーパラメータ**として知られています。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 学習する\n",
    "\n",
    "いよいよ学習をスタートします！今回は分類問題なので、`softmax_cross_entropy`というロス関数を使って最小化すべきロスの値を計算します。\n",
    "\n",
    "まず、ネットワークにデータを渡して、出てきた出力と、入力データに対応する正解ラベルを、`Function`の一種でありスカラ値を返す**ロス関数**に渡し、ロス（最小化したい値）の計算を行います。ロスは、`chainer.Variable`のオブジェクトになっています。そして、この`Variable`は、**今まで自分にどんな計算が施されたかを辿れるようになっています。**この仕組みが、Define-by-Run [[Tokui 2015]](http://learningsys.org/papers/LearningSys_2015_paper_33.pdf)とよばれる発明の中心的な役割を果たしています。\n",
    "\n",
    "ここでは誤差逆伝播法自体の説明は割愛しますが、**計算したロスに対する勾配をネットワークに逆向きに流していく**処理は、Chainerではネットワークが吐き出した`Variable`が持つ`backward()`メソッドを呼ぶだけでできます。これを呼ぶと、前述のようにこれまでの計算過程を逆向きに遡って**誤差逆伝播用の計算グラフを構築し**、途中のパラメータの勾配を連鎖率を使って計算してくれます。（詳しくは筆者が[日本ソフトウェア科学会で行ったチュートリアルの資料](https://www.slideshare.net/mitmul/chainer-79942361)をご覧ください。）\n",
    "\n",
    "こうして計算された各パラメータに対する勾配を使って、先程`Optimizer`を作成する際に指定したアルゴリズムを使ってネットワークパラメータの更新（＝学習）が行われるわけです。\n",
    "\n",
    "まとめると、今回1回の更新処理の中で行うのは、以下の4項目です。\n",
    "\n",
    "1. ネットワークにデータを渡して出力`y`を得る\n",
    "2. 出力`y`と正解ラベル`t`を使って、最小化すべきロスの値を`softmax_cross_entropy`関数で計算する\n",
    "3. `softmax_cross_entropy`関数の出力（`Variable`）の`backward()`メソッドを呼んで、ネットワークの全てのパラメータの勾配を誤差逆伝播法で計算する\n",
    "4. Optimizerの`update`メソッドを呼び、3.で計算した勾配を使って全パラメータを更新する\n",
    "\n",
    "パラメータの更新は、何度も何度も繰り返し行います。一度の更新に用いられるデータは、ネットワークに入力されたバッチサイズ分だけ束ねられたデータのみです。そのため、データセット全体のデータを使うために、次のミニバッチを入力して再度更新、その次のミニバッチを使ってまた更新、ということを繰り返すわけです。そのため、この過程を学習ループと呼んでいます。\n",
    "\n",
    "#### NOTE: ロス関数\n",
    "\n",
    "ちなみに、ロス関数は、例えば分類問題ではなく簡単な回帰問題を解きたいような場合、`F.softmax_cross_entropy`の代わりに`F.mean_squared_error`などを用いることもできます。他にも、いろいろな問題設定に対応するために様々なロス関数がChainerには用意されています。こちらからその一覧を見ることができます：\n",
    "\n",
    "- [Chainerで使えるロス関数一覧](http://docs.chainer.org/en/stable/reference/functions.html#loss-functions)\n",
    "\n",
    "### 学習ループのコード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:01 train_loss:0.9242 val_loss:0.9075 val_accuracy:0.8039\n",
      "epoch:02 train_loss:0.4960 val_loss:0.5198 val_accuracy:0.8671\n",
      "epoch:03 train_loss:0.4074 val_loss:0.4234 val_accuracy:0.8832\n",
      "epoch:04 train_loss:0.4202 val_loss:0.3756 val_accuracy:0.8946\n",
      "epoch:05 train_loss:0.4282 val_loss:0.3475 val_accuracy:0.9028\n",
      "epoch:06 train_loss:0.2207 val_loss:0.3285 val_accuracy:0.9067\n",
      "epoch:07 train_loss:0.5142 val_loss:0.3118 val_accuracy:0.9117\n",
      "epoch:08 train_loss:0.2038 val_loss:0.3009 val_accuracy:0.9137\n",
      "epoch:09 train_loss:0.3021 val_loss:0.2905 val_accuracy:0.9160\n",
      "epoch:10 train_loss:0.2317 val_loss:0.2796 val_accuracy:0.9203\n",
      "test_accuracy:0.9375\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from chainer.dataset import concat_examples\n",
    "from chainer.cuda import to_cpu\n",
    "\n",
    "max_epoch = 10\n",
    "\n",
    "while train_iter.epoch < max_epoch:\n",
    "    \n",
    "    # ---------- 学習の1イテレーション ----------\n",
    "    train_batch = train_iter.next()\n",
    "    x, t = concat_examples(train_batch, gpu_id)\n",
    "    \n",
    "    # 予測値の計算\n",
    "    y = net(x)\n",
    "\n",
    "    # ロスの計算\n",
    "    loss = F.softmax_cross_entropy(y, t)\n",
    "\n",
    "    # 勾配の計算\n",
    "    net.cleargrads()\n",
    "    loss.backward()\n",
    "\n",
    "    # パラメータの更新\n",
    "    optimizer.update()\n",
    "    # --------------- ここまで ----------------\n",
    "\n",
    "    # 1エポック終了ごとにValidationデータに対する予測精度を測って、\n",
    "    # モデルの汎化性能が向上していることをチェックしよう\n",
    "    if train_iter.is_new_epoch:  # 1 epochが終わったら\n",
    "\n",
    "        # ロスの表示\n",
    "        print('epoch:{:02d} train_loss:{:.04f} '.format(\n",
    "            train_iter.epoch, float(to_cpu(loss.data))), end='')\n",
    "\n",
    "        valid_losses = []\n",
    "        valid_accuracies = []\n",
    "        while True:\n",
    "            valid_batch = valid_iter.next()\n",
    "            x_valid, t_valid = concat_examples(valid_batch, gpu_id)\n",
    "\n",
    "            # Validationデータをforward\n",
    "            with chainer.using_config('train', False), \\\n",
    "                    chainer.using_config('enable_backprop', False):\n",
    "                y_valid = net(x_valid)\n",
    "\n",
    "            # ロスを計算\n",
    "            loss_valid = F.softmax_cross_entropy(y_valid, t_valid)\n",
    "            valid_losses.append(to_cpu(loss_valid.array))\n",
    "\n",
    "            # 精度を計算\n",
    "            accuracy = F.accuracy(y_valid, t_valid)\n",
    "            accuracy.to_cpu()\n",
    "            valid_accuracies.append(accuracy.array)\n",
    "                        \n",
    "            if valid_iter.is_new_epoch:\n",
    "                valid_iter.reset()\n",
    "                break\n",
    "\n",
    "        print('val_loss:{:.04f} val_accuracy:{:.04f}'.format(\n",
    "            np.mean(valid_losses), np.mean(valid_accuracies)))\n",
    "        \n",
    "# テストデータでの評価\n",
    "test_accuracies = []\n",
    "while True:\n",
    "    test_batch = test_iter.next()\n",
    "    x_test, t_test = concat_examples(test_batch, gpu_id)\n",
    "\n",
    "    # テストデータをforward\n",
    "    with chainer.using_config('train', False), \\\n",
    "            chainer.using_config('enable_backprop', False):\n",
    "        y_test = net(x_test)\n",
    "\n",
    "    # 精度を計算\n",
    "    accuracy = F.accuracy(y_valid, t_valid)\n",
    "    accuracy.to_cpu()\n",
    "    test_accuracies.append(accuracy.array)\n",
    "\n",
    "    if test_iter.is_new_epoch:\n",
    "        test_iter.reset()\n",
    "        break\n",
    "\n",
    "print('test_accuracy:{:.04f}'.format(np.mean(test_accuracies)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`val_accuracy`に着目してみると、最終的におおよそ92%程度の精度で手書きの数字が分類できるようになりました。**学習終了後**に、ループの中でValidationデータセットを使ってモデルの汎化性能をおおまかにチェックしているのと同様にして、**テスト用のデータセットを用いて学習が終了したネットワークの評価を行っています。**テストデータでの評価結果は、およそ93.75%の正解率となりました。\n",
    "\n",
    "### 5.1 ValidationやTestを行う際の注意点\n",
    "\n",
    "ここで、ValidationにせよTestにせよ、「評価」を行う際には注意すべき点があります。学習は行わない、評価のためだけのデータをネットワークに渡して出力を計算している部分（例えば、`y_test = net(x_test)`）では、それらの行を2つのコンテキストでくくっています。\n",
    "\n",
    "#### `chainer.using_config('train', False)`\n",
    "\n",
    "まず、今回は学習時と推論時で動作が異なる関数は含まれていないため、実際の効力は持ちませんが、Validationやテストのために推論を行うときは`chainer.config.train = False`とします。以下のように、`chainer.using_config('train', False)`をwith構文と共に使えば、その中では`chainer.config.train = False`となります。\n",
    "\n",
    "```python\n",
    "with chainer.using_config('train', False):\n",
    "    --- 何か推論処理 ---\n",
    "```\n",
    "\n",
    "これは、以下のようにするのと同じことです。\n",
    "\n",
    "```python\n",
    "chainer.config.train = False\n",
    "\n",
    "--- 何か推論処理 ---\n",
    "```\n",
    "\n",
    "ただし、Pythonのコンテキストを利用しない場合は、一度このようにどこかで書くと、それ以降この設定はグローバルにずっと有効になることに注意してください。（推論したあと再び学習を行うという場合は、再度`chainer.config.train = True`などのようにすることが必要になります。`chainer.config`以下の規定の値に何かを代入することはグローバルに作用しますので、次に説明する`enable_backprop`についても同様です。）\n",
    "\n",
    "#### `chainer.using_config('enable_backprop', False)`\n",
    "\n",
    "次に、今回は評価に用いる出力の計算後にロス関数の各パラメータについての勾配は必要ないので、内部に計算グラフを保持しておく必要もないため、`chainer.using_config('enable_backprop', False)`として**無駄な計算グラフの構築を行わないようにし、メモリ消費量を節約しています。**\n",
    "\n",
    "#### NOTE: ChainerのConfig\n",
    "\n",
    "Chainerにはこの他にも、いくつかのグローバルなConfigがプリセットとして用意されています。また、`chainer.config`以下にユーザが自由な設定値を置くこともできます。詳しくはこちらを一読してください：[Configuring Chainer](https://docs.chainer.org/en/stable/reference/configuration.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 学習済みモデルを保存する\n",
    "\n",
    "学習が終わったら、その結果を保存します。Chainerには、2種類のフォーマットで学習済みネットワークをシリアライズする機能が用意されています。一つはHDF5形式で、もう一つはNumPyのNPZ形式でネットワークを保存するものです。今回は、追加ライブラリのインストールが必要なHDF5ではなく、NumPy標準機能で提供されているシリアライズ機能（`numpy.savez()`）を利用したNPZ形式でのモデルの保存を行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chainer import serializers\n",
    "\n",
    "serializers.save_npz('my_mnist.model', net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 jovyan users 333995 May  1 07:00 my_mnist.model\r\n"
     ]
    }
   ],
   "source": [
    "# ちゃんと保存されていることを確認\n",
    "%ls -la my_mnist.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 保存したモデルを読み込んで推論する\n",
    "\n",
    "学習したネットワークを、それを使って数字の分類がしたい誰かに渡して、使ってもらうにはどうしたら良いでしょうか。もっともシンプルな方法は、ネットワークの定義がかかれたPythonファイルと、今しがた保存したNPZファイルを渡して、以下のように使うことです。以下のコードの前に、渡したネットワーク定義のファイルからネットワークのクラス（ここでは`MLP`）が読み込まれていることを前提とします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# まず同じネットワークのオブジェクトを作る\n",
    "infer_net = MLP()\n",
    "\n",
    "# そのオブジェクトに保存済みパラメータをロードする\n",
    "serializers.load_npz('my_mnist.model', infer_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上で準備が整いました。それでは、試しにテストデータの中から一つ目の画像を取ってきて、それに対する分類を行ってみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fade55b82b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "元の形： (784,) -> ミニバッチの形にしたあと： (1, 784)\n",
      "ネットワークの予測: 7\n"
     ]
    }
   ],
   "source": [
    "gpu_id = -1 # GPUの設定をしていないため、取り急ぎ0から-1に変更。  # CPUで計算をしたい場合は、-1を指定してください\n",
    "\n",
    "if gpu_id >= 0:\n",
    "    infer_net.to_gpu(gpu_id)\n",
    "\n",
    "# 1つ目のテストデータを取り出します\n",
    "x, t = test[0]  #  tは使わない\n",
    "\n",
    "# どんな画像か表示してみます\n",
    "plt.imshow(x.reshape(28, 28), cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "# ミニバッチの形にする（複数の画像をまとめて推論に使いたい場合は、サイズnのミニバッチにしてまとめればよい）\n",
    "print('元の形：', x.shape, end=' -> ')\n",
    "\n",
    "x = x[None, ...]\n",
    "\n",
    "print('ミニバッチの形にしたあと：', x.shape)\n",
    "\n",
    "# ネットワークと同じデバイス上にデータを送る\n",
    "x = infer_net.xp.asarray(x)\n",
    "\n",
    "# モデルのforward関数に渡す\n",
    "with chainer.using_config('train', False), chainer.using_config('enable_backprop', False):\n",
    "    y = infer_net(x)\n",
    "\n",
    "# Variable形式で出てくるので中身を取り出す\n",
    "y = y.array\n",
    "\n",
    "# 結果をCPUに送る\n",
    "y = to_cpu(y)\n",
    "\n",
    "# 予測確率の最大値のインデックスを見る\n",
    "pred_label = y.argmax(axis=1)\n",
    "\n",
    "print('ネットワークの予測:', pred_label[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ネットワークの予測は7でした。画像を見る限り、当たっていそうですね！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainerを使ってみよう\n",
    "\n",
    "Chainerは、これまで書いてきたような学習ループを隠蔽する`Trainer`という機能を提供しています。これを使うと、学習ループを陽に書く必要がなくなり、またいろいろな便利なExtentionを使うことで、学習過程でのロスカーブの可視化や、ログの保存などが楽になります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. データセット・Iterator・ネットワークの準備\n",
    "\n",
    "これらはループを自分で書く場合と同じなので、まとめてしまいます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_seed(0)\n",
    "\n",
    "train_val, test = mnist.get_mnist()\n",
    "train, valid = split_dataset_random(train_val, 50000, seed=0)\n",
    "\n",
    "batchsize = 128\n",
    "\n",
    "train_iter = iterators.SerialIterator(train, batchsize)\n",
    "valid_iter = iterators.SerialIterator(valid, batchsize, False, False)\n",
    "test_iter = iterators.SerialIterator(test, batchsize, False, False)\n",
    "\n",
    "gpu_id = -1 # GPUの設定をしていないため、取り急ぎ0から-1に変更。 # CPUを用いたい場合は、-1を指定してください\n",
    "\n",
    "net = MLP()\n",
    "\n",
    "if gpu_id >= 0:\n",
    "    net.to_gpu(gpu_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Updaterの準備\n",
    "\n",
    "ここからが学習ループを自分で書く場合と異なる部分です。ループを自分で書く場合には、データセットからバッチサイズ分のデータをとってきてミニバッチに束ねて、それをネットワークに入力して予測を作り、それを正解と比較し、ロスを計算してバックワード（誤差逆伝播）をして、`Optimizer`によってパラメータを更新する、というところまでを、以下のように書いていました。\n",
    "\n",
    "```python\n",
    "# ---------- 学習の1イテレーション ----------\n",
    "train_batch = train_iter.next()\n",
    "x, t = concat_examples(train_batch, gpu_id)\n",
    "\n",
    "# 予測値の計算\n",
    "y = net(x)\n",
    "\n",
    "# ロスの計算\n",
    "loss = F.softmax_cross_entropy(y, t)\n",
    "\n",
    "# 勾配の計算\n",
    "net.cleargrads()\n",
    "loss.backward()\n",
    "\n",
    "# パラメータの更新\n",
    "optimizer.update()\n",
    "```\n",
    "\n",
    "これらの処理を、まるっと`Updater`はまとめてくれます。これを行うために、**`Updater`には`Iterator`と`Optimizer`を渡してやります。** `Iterator`はデータセットオブジェクトを持っていて、そこからミニバッチを作り、`Optimizer`は最適化対象のネットワークを持っていて、それを使って前進計算とロスの計算・パラメータのアップデートをすることができます。そのため、この2つを渡しておけば、上記の処理を`Updater`内で全部行ってもらえるというわけです。では、`Updater`オブジェクトを作成してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chainer import training\n",
    "\n",
    "gpu_id = -1 # GPUの設定をしていないため、取り急ぎ0から-1に変更。 # CPUを使いたい場合は-1を指定してください\n",
    "\n",
    "# ネットワークをClassifierで包んで、ロスの計算などをモデルに含める\n",
    "net = L.Classifier(net)\n",
    "\n",
    "# 最適化手法の選択\n",
    "optimizer = optimizers.SGD(lr=0.01).setup(net)\n",
    "\n",
    "# UpdaterにIteratorとOptimizerを渡す\n",
    "updater = training.StandardUpdater(train_iter, optimizer, device=gpu_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE\n",
    "\n",
    "ここでは、ネットワークを`L.Classifier`で包んでいます。`L.Classifier`は一種の`Chain`になっていて、渡されたネットワーク自体を`predictor`というattributeに持ち、**ロス計算を行う機能を追加してくれます。**こうすると、`net()`はデータ`x`だけでなくラベル`t`も取るようになり、まず渡されたデータを`predictor`に通して予測を作り、それを`t`と比較して**ロスの`Variable`を返すようになります。**ロス関数として何を用いるかはデフォルトでは`F.softmax_cross_entropy`となっていますが、`L.Classifier`の引数`lossfunc`にロス計算を行う関数を渡してやれば変更することができるため、Classifierという名前ながら回帰問題などのロス計算機能の追加にも使うことができます。（`L.Classifier(net, lossfun=L.mean_squared_error, compute_accuracy=False)`のようにする）\n",
    "\n",
    "`StandardUpdater`は前述のような`Updater`の担当する処理を遂行するための最もシンプルなクラスです。この他にも複数のGPUを用いるための`ParallelUpdater`などが用意されています。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Trainerの準備\n",
    "\n",
    "実際に学習ループ部分を隠蔽しているのは`Updater`なので、これがあればもう学習を始められそうですが、`Trainer`はさらに`Updater`を受け取って学習全体の管理を行う機能を提供しています。例えば、**データセットを何周したら学習を終了するか(stop_trigger)** や、**途中のロスの値をどのファイルに保存したいか**、**ロスカーブを可視化した画像ファイルを保存するかどうか**など、学習全体の設定として必須・もしくはあると便利な色々な機能を提供しています。\n",
    "\n",
    "必須なものとしては学習終了のタイミングを指定する`stop_trigger`がありますが、これは`Trainer`オブジェクトを作成するときのコンストラクタで指定します。指定の方法は単純で、`(長さ, 単位)`という形のタプルを与えればよいだけです。「長さ」には数字を、「単位」には`'iteration'`もしくは`'epoch'`のいずれかの文字列を指定します。こうすると、たとえば100 epoch（データセット100周）で学習を終了してください、とか、1000 iteration（1000回更新）で学習を終了してください、といったことが指定できます。`Trainer`を作るときに、`stop_trigger`を指定しないと、学習は自動的には止まりません。\n",
    "\n",
    "では、実際に`Trainer`オブジェクトを作ってみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epoch = 10\n",
    "\n",
    "# TrainerにUpdaterを渡す\n",
    "trainer = training.Trainer(\n",
    "    updater, (max_epoch, 'epoch'), out='mnist_result')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`out`引数では、この次に説明する`Extension`を使って、ログファイルやロスの変化の過程を描画したグラフの画像ファイルなどを保存するディレクトリを指定しています。\n",
    "\n",
    "Trainerと、その内側にあるいろいろなオブジェクトの関係は、図にまとめると以下のようになっています。このイメージを持っておくと自分で部分的に改造したりする際に便利だと思います。\n",
    "\n",
    "![image](https://qiita-image-store.s3.amazonaws.com/0/17934/a751df31-b999-f692-d839-488c26b1c48a.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. TrainerにExtensionを追加する\n",
    "\n",
    "`Trainer`を使う利点として、\n",
    "\n",
    "- ログを自動的にファイルに保存（`LogReport`)\n",
    "- ターミナルに定期的にロスなどの情報を表示（`PrintReport`）\n",
    "- ロスを定期的にグラフで可視化して画像として保存（`PlotReport`)\n",
    "- 定期的にモデルやOptimizerの状態を自動シリアライズ（`snapshot`）\n",
    "- 学習の進捗を示すプログレスバーを表示（`ProgressBar`）\n",
    "- ネットワークの構造をGraphvizのdot形式で保存（`dump_graph`）\n",
    "- ネットワークのパラメータの平均や分散などの統計情報を出力（`ParameterStatistics`）\n",
    "\n",
    "などなどの様々な便利な機能を簡単に利用することができる点があります。これらの機能を利用するには、`Trainer`オブジェクトに対して`extend`メソッドを使って追加したい`Extension`のオブジェクトを渡してやるだけです。では実際に幾つかの`Extension`を追加してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chainer.training import extensions\n",
    "\n",
    "trainer.extend(extensions.LogReport())\n",
    "trainer.extend(extensions.snapshot(filename='snapshot_epoch-{.updater.epoch}'))\n",
    "trainer.extend(extensions.Evaluator(valid_iter, net, device=gpu_id), name='val')\n",
    "trainer.extend(extensions.PrintReport(['epoch', 'main/loss', 'main/accuracy', 'val/main/loss', 'val/main/accuracy', 'l1/W/data/std', 'elapsed_time']))\n",
    "trainer.extend(extensions.ParameterStatistics(net.predictor.l1, {'std': np.std}))\n",
    "trainer.extend(extensions.PlotReport(['l1/W/data/std'], x_key='epoch', file_name='std.png'))\n",
    "trainer.extend(extensions.PlotReport(['main/loss', 'val/main/loss'], x_key='epoch', file_name='loss.png'))\n",
    "trainer.extend(extensions.PlotReport(['main/accuracy', 'val/main/accuracy'], x_key='epoch', file_name='accuracy.png'))\n",
    "trainer.extend(extensions.dump_graph('main/loss'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `LogReport`\n",
    "\n",
    "`epoch`や`iteration`ごとの`loss`, `accuracy`などを自動的に集計し、`Trainer`の`out`引数で指定した出力ディレクトリに`log`というファイル名で保存します。\n",
    "\n",
    "### `snapshot`\n",
    "\n",
    "`Trainer`の`out`引数で指定した出力ディレクトリに`Trainer`オブジェクトを指定されたタイミング（デフォルトでは1エポックごと）に保存します。`Trainer`オブジェクトは上述のように`Updater`を持っており、この中に`Optimizer`とモデルが保持されているため、この`Extension`でスナップショットをとっておけば、学習の復帰や学習済みモデルを使った推論などが学習終了後にも可能になります。\n",
    "\n",
    "### `dump_graph`\n",
    "\n",
    "指定された`Variable`オブジェクトから辿れる計算グラフをGraphvizのdot形式で保存します。保存先は`Trainer`の`out`引数で指定した出力ディレクトリです。\n",
    "\n",
    "### `Evaluator`\n",
    "\n",
    "評価用のデータセットの`Iterator`と、学習に使うモデルのオブジェクトを渡しておくことで、学習中のモデルを指定されたタイミングで評価用データセットを用いて評価します。内部では、`chainer.config.using_config('train', False)`が自動的に行われます。`backprop_enable`を`False`にすることは行われないため、メモリ使用効率はデフォルトでは最適ではありませんが、基本的には`Evaluator`を使えば評価を行うという点において問題はありません。\n",
    "\n",
    "### `PrintReport`\n",
    "\n",
    "`Reporter`によって集計された値を標準出力に出力します。このときどの値を出力するかを、リストの形で与えます。\n",
    "\n",
    "### `PlotReport`\n",
    "\n",
    "引数のリストで指定された値の変遷を`matplotlib`ライブラリを使ってグラフに描画し、出力ディレクトリに`file_name`引数で指定されたファイル名で画像として保存します。\n",
    "\n",
    "### `ParameterStatistics`\n",
    "\n",
    "指定したレイヤ（Link）が持つパラメータの平均・分散・最小値・最大値などなどの統計情報を計算して、ログに保存します。パラメータが発散していないかなどをチェックするのに便利です。\n",
    "\n",
    "---\n",
    "\n",
    "これらの`Extension`は、ここで紹介した以外にも、例えば`trigger`によって個別に作動するタイミングを指定できるなどのいくつかのオプションを持っており、より柔軟に組み合わせることができます。詳しくは公式のドキュメントを見てください\n",
    "\n",
    "- [ChainerのTrainer extension一覧](http://docs.chainer.org/en/stable/reference/extensions.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 学習を開始する\n",
    "\n",
    "学習を開始するには、`Trainer`オブジェクトのメソッド`run`を呼ぶだけです！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "cannot run training loop multiple times",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-041e2033e90a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/chainer/training/trainer.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, show_loop_exception_msg)\u001b[0m\n\u001b[1;32m    273\u001b[0m         \"\"\"\n\u001b[1;32m    274\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_done\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cannot run training loop multiple times'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cannot run training loop multiple times"
     ]
    }
   ],
   "source": [
    "trainer.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "初めに取り組んだ学習ループを自分で書いた場合よりもより短いコードで、リッチなログ情報とともに、下記で表示してみるようなグラフなども作りつつ、同様の結果を得ることができました。1層目の全結合層の重み行列の値の標準偏差が、学習の進行とともに徐々に大きくなっていっているのも見て取れて、面白いですね。\n",
    "\n",
    "では、保存されているロスのグラフを確認してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='mnist_result/loss.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "精度のグラフも見てみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(filename='mnist_result/accuracy.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "もう少し学習を続ければ、まだ多少精度の向上が図れそうな雰囲気がありますね。\n",
    "\n",
    "ついでに、`dump_graph`という`Extension`が出力した計算グラフを、`Graphviz`を使って画像化して見てみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bash: line 1: dot: command not found\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "dot -Tpng mnist_result/cg.dot -o mnist_result/cg.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'mnist_result/cg.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-3a5a0f910d7f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mnist_result/cg.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, url, filename, format, embed, width, height, retina, unconfined, metadata)\u001b[0m\n\u001b[1;32m   1146\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munconfined\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munconfined\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m         super(Image, self).__init__(data=data, url=url, filename=filename, \n\u001b[0;32m-> 1148\u001b[0;31m                 metadata=metadata)\n\u001b[0m\u001b[1;32m   1149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwidth\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'width'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, url, filename, metadata)\u001b[0m\n\u001b[1;32m    607\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 609\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    610\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mreload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1177\u001b[0m         \u001b[0;34m\"\"\"Reload the raw data from file or URL.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1178\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1179\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1180\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretina\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retina_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mreload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    632\u001b[0m         \u001b[0;34m\"\"\"Reload the raw data from file or URL.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_flags\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'mnist_result/cg.png'"
     ]
    }
   ],
   "source": [
    "Image(filename='mnist_result/cg.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上から下へ向かって、データやパラメータがどのような`Function`に渡されて計算が行われ、ロスを表す`Variable`が出力されたかが分かります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. テストデータで評価する\n",
    "\n",
    "上でもValidationデータに対しての評価を学習中に行うために使用されているTrainer Extensionの一つであるEvaluatorは、Trainerと関係なく独立して使うこともできます。以下のようにして`Iterator`とネットワークのオブジェクト（`net`）、使用するデバイスIDを渡してEvaluatorオブジェクトを作成し、これを関数として実行するだけです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_evaluator = extensions.Evaluator(test_iter, net, device=gpu_id)\n",
    "results = test_evaluator()\n",
    "print('Test accuracy:', results['main/accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 学習済みモデルで推論する\n",
    "\n",
    "それでは、Trainer Extensionのsnapshotが自動的に保存したネットワークのスナップショットから学習済みパラメータを読み込んで、学習ループを書いて学習したときと同様に1番目のテストデータで推論を行ってみましょう。\n",
    "\n",
    "ここで注意すべきは、snapshotが保存するnpzファイルはTrainer全体のスナップショットであるため、extensionの内部のパラメータなども一緒に保存されています。これは、学習自体を再開するために必要だからです。しかし、今回はネットワークのパラメータだけを読み込めば良いので、`serializers.load_npz()`のpath引数にネットワーク部分までのパス（`updater/model:main/predictor/`）を指定しています。こうすることで、ネットワークのオブジェクトにパラメータだけを読み込むことができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_seed(0)\n",
    "\n",
    "infer_net = MLP()\n",
    "serializers.load_npz(\n",
    "    'mnist_result/snapshot_epoch-10',\n",
    "    infer_net, path='updater/model:main/predictor/')\n",
    "\n",
    "if gpu_id >= 0:\n",
    "    infer_net.to_gpu(gpu_id)\n",
    "\n",
    "x, t = test[0]\n",
    "plt.imshow(x.reshape(28, 28), cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "x = infer_net.xp.asarray(x[None, ...])\n",
    "with chainer.using_config('train', False), chainer.using_config('enable_backprop', False):\n",
    "    y = infer_net(x)\n",
    "y = to_cpu(y.array)\n",
    "\n",
    "print('予測ラベル:', y.argmax(axis=1)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "無事正解できていますね。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 新しいネットワークを書いてみよう\n",
    "\n",
    "ここでは、MNISTデータセットではなくCIFAR10という32x32サイズの小さなカラー画像に10クラスのいずれかのラベルがついたデータセットを用いて、いろいろなモデルを自分で書いて試行錯誤する流れを体験してみます。\n",
    "\n",
    "| airplane | automobile | bird | cat | deer | dog | frog | horse | ship | truck |\n",
    "|:--------:|:----------:|:----:|:---:|:----:|:---:|:----:|:-----:|:----:|:-----:|\n",
    "| ![](https://www.cs.toronto.edu/~kriz/cifar-10-sample/airplane4.png) | ![](https://www.cs.toronto.edu/~kriz/cifar-10-sample/automobile4.png) | ![](https://www.cs.toronto.edu/~kriz/cifar-10-sample/bird4.png) | ![](https://www.cs.toronto.edu/~kriz/cifar-10-sample/cat4.png) | ![](https://www.cs.toronto.edu/~kriz/cifar-10-sample/deer4.png) | ![](https://www.cs.toronto.edu/~kriz/cifar-10-sample/dog4.png) | ![](https://www.cs.toronto.edu/~kriz/cifar-10-sample/frog4.png) | ![](https://www.cs.toronto.edu/~kriz/cifar-10-sample/horse4.png) | ![](https://www.cs.toronto.edu/~kriz/cifar-10-sample/ship4.png) | ![](https://www.cs.toronto.edu/~kriz/cifar-10-sample/truck4.png) |\n",
    "\n",
    "## 1. ネットワークの定義\n",
    "\n",
    "ここでは、さきほど試した全結合層だけからなるネットワークではなく、畳込み層を持つネットワークを定義してみます。3つの畳み込み層を持ち、2つの全結合層がそのあとに続いています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNet(chainer.Chain):\n",
    "    \n",
    "    def __init__(self, n_out):\n",
    "        super(MyNet, self).__init__()\n",
    "        with self.init_scope():\n",
    "            self.conv1 = L.Convolution2D(None, 32, 3, 3, 1)\n",
    "            self.conv2 = L.Convolution2D(32, 64, 3, 3, 1)\n",
    "            self.conv3 = L.Convolution2D(64, 128, 3, 3, 1)\n",
    "            self.fc4 = L.Linear(None, 1000)\n",
    "            self.fc5 = L.Linear(1000, n_out)\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        h = F.relu(self.conv1(x))\n",
    "        h = F.relu(self.conv2(h))\n",
    "        h = F.relu(self.conv3(h))\n",
    "        h = F.relu(self.fc4(h))\n",
    "        h = self.fc5(h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 学習\n",
    "\n",
    "ここで、あとから別のネットワークも簡単に同じ設定で訓練できるよう、`train`関数を作っておきます。これは、\n",
    "\n",
    "- ネットワークのオブジェクト\n",
    "- バッチサイズ\n",
    "- 使用するGPU ID\n",
    "- 学習を終了するエポック数\n",
    "- データセットオブジェクト\n",
    "- 学習率の初期値\n",
    "- 学習率減衰のタイミング\n",
    "\n",
    "などを渡すと、内部で`Trainer`を用いて渡されたデータセットを使ってネットワークを訓練し、学習が終了した状態のネットワークを返してくれる関数です。`Trainer.run()`が終了した後に、テストデータセットを使って評価まで行ってくれます。先程のMNISTでの例と違い、最適化手法にはMomentumSGDを用い、ExponentialShiftというExtentionを使って、指定したタイミングごとに学習率を減衰させるようにしてみます。\n",
    "\n",
    "また、ここでは`cifar.get_cifar10()`が返す学習用データセットのうち9割のデータを`train`、残りの1割を`valid`として使うようにしています。\n",
    "\n",
    "この`train`関数を用いて、上で定義した`MyModel`モデルを訓練してみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chainer.datasets import cifar\n",
    "\n",
    "\n",
    "def train(network_object, batchsize=128, gpu_id=0, max_epoch=20, train_dataset=None, valid_dataset=None, test_dataset=None, postfix='', base_lr=0.01, lr_decay=None):\n",
    "\n",
    "    # 1. Dataset\n",
    "    if train_dataset is None and valid_dataset is None and test_dataset is None:\n",
    "        train_val, test = cifar.get_cifar10()\n",
    "        train_size = int(len(train_val) * 0.9)\n",
    "        train, valid = split_dataset_random(train_val, train_size, seed=0)\n",
    "    else:\n",
    "        train, valid, test = train_dataset, valid_dataset, test_dataset\n",
    "\n",
    "    # 2. Iterator\n",
    "    train_iter = iterators.MultiprocessIterator(train, batchsize)\n",
    "    valid_iter = iterators.MultiprocessIterator(valid, batchsize, False, False)\n",
    "\n",
    "    # 3. Model\n",
    "    net = L.Classifier(network_object)\n",
    "\n",
    "    # 4. Optimizer\n",
    "    optimizer = optimizers.MomentumSGD(lr=base_lr).setup(net)\n",
    "    optimizer.add_hook(chainer.optimizer.WeightDecay(0.0005))\n",
    "\n",
    "    # 5. Updater\n",
    "    updater = training.StandardUpdater(train_iter, optimizer, device=gpu_id)\n",
    "\n",
    "    # 6. Trainer\n",
    "    trainer = training.Trainer(updater, (max_epoch, 'epoch'), out='{}_cifar10_{}result'.format(network_object.__class__.__name__, postfix))\n",
    "    \n",
    "    # 7. Trainer extensions\n",
    "    trainer.extend(extensions.LogReport())\n",
    "    trainer.extend(extensions.observe_lr())\n",
    "    trainer.extend(extensions.Evaluator(valid_iter, net, device=gpu_id), name='val')\n",
    "    trainer.extend(extensions.PrintReport(['epoch', 'main/loss', 'main/accuracy', 'val/main/loss', 'val/main/accuracy', 'elapsed_time', 'lr']))\n",
    "    trainer.extend(extensions.PlotReport(['main/loss', 'val/main/loss'], x_key='epoch', file_name='loss.png'))\n",
    "    trainer.extend(extensions.PlotReport(['main/accuracy', 'val/main/accuracy'], x_key='epoch', file_name='accuracy.png'))\n",
    "    if lr_decay is not None:\n",
    "        trainer.extend(extensions.ExponentialShift('lr', 0.1), trigger=lr_decay)\n",
    "    trainer.run()\n",
    "    del trainer\n",
    "    \n",
    "    # 8. Evaluation\n",
    "    test_iter = iterators.MultiprocessIterator(test, batchsize, False, False)\n",
    "    test_evaluator = extensions.Evaluator(test_iter, net, device=gpu_id)\n",
    "    results = test_evaluator()\n",
    "    print('Test accuracy:', results['main/accuracy'])\n",
    "    \n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = train(MyNet(10), gpu_id=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習が20エポックまで終わりました。ロスと精度のプロットを見てみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='MyNet_cifar10_result/loss.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='MyNet_cifar10_result/accuracy.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習データでの精度（`main/accuracy`)は77%程度まで到達していますが、テストデータでのロス（`val/main/loss`）は途中から下げ止まり、精度（`val/main/accuracy`）も60%前後で頭打ちになってしまっています。表示されたログの最後の行を見ると、テストデータでの精度も同様に60%程度だったようです。学習データでは良い精度が出ているが、 テストデータでは精度が良くないということなので、**モデルが学習データにオーバーフィッティングしている**と思われます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 学習済みネットワークを使った予測\n",
    "\n",
    "テスト精度は60%程度でしたが、試しにこの学習済みネットワークを使っていくつかのテスト画像を分類させてみましょう。あとで使いまわせるように`predict`関数を作っておきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "             'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "def predict(net, image_id):\n",
    "    _, test = cifar.get_cifar10()\n",
    "    x, t = test[image_id]\n",
    "    net.to_cpu()\n",
    "    with chainer.using_config('train', False), chainer.using_config('enable_backprop', False):\n",
    "        y = net.predictor(x[None, ...]).data.argmax(axis=1)[0]\n",
    "    print('predicted_label:', cls_names[y])\n",
    "    print('answer:', cls_names[t])\n",
    "\n",
    "    plt.imshow(x.transpose(1, 2, 0))\n",
    "    plt.show()\n",
    "\n",
    "for i in range(10, 15):\n",
    "    predict(net, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "うまく分類できているものもあれば、そうでないものもありました。ネットワークの学習に使用したデータセット上ではほぼ百発百中で正解できるとしても、未知のデータ、すなわちテストデータセットにある画像に対して高精度な予測ができなければ、意味がありません[^NN]。テストデータでの精度は、モデルの**汎化性能**に関係していると言われます。\n",
    "\n",
    "どうすれば高い汎化性能を持つネットワークを設計し、学習することができるでしょうか？（そんなことが簡単に分かったら苦労しない。）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. もっと深いネットワークを定義してみよう\n",
    "\n",
    "では、上のネットワークよりもよりたくさんの層を持つネットワークを定義してみましょう。ここでは、1層の畳み込みネットワークを`ConvBlock`、1層の全結合ネットワークを`LinearBlock`として定義し、これをたくさんシーケンシャルに積み重ねる方法で大きなネットワークを定義してみます。\n",
    "\n",
    "### 構成要素を定義する\n",
    "\n",
    "まず、今目指している大きなネットワークの構成要素となる`ConvBlock`と`LinearBlock`を定義してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(chainer.Chain):\n",
    "    \n",
    "    def __init__(self, n_ch, pool_drop=False):\n",
    "        w = chainer.initializers.HeNormal()\n",
    "        super(ConvBlock, self).__init__()\n",
    "        with self.init_scope():\n",
    "            self.conv = L.Convolution2D(None, n_ch, 3, 1, 1, nobias=True, initialW=w)\n",
    "            self.bn = L.BatchNormalization(n_ch)\n",
    "        self.pool_drop = pool_drop\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        h = F.relu(self.bn(self.conv(x)))\n",
    "        if self.pool_drop:\n",
    "            h = F.max_pooling_2d(h, 2, 2)\n",
    "            h = F.dropout(h, ratio=0.25)\n",
    "        return h\n",
    "    \n",
    "class LinearBlock(chainer.Chain):\n",
    "    \n",
    "    def __init__(self, drop=False):\n",
    "        w = chainer.initializers.HeNormal()\n",
    "        super(LinearBlock, self).__init__()\n",
    "        with self.init_scope():\n",
    "            self.fc = L.Linear(None, 1024, initialW=w)\n",
    "        self.drop = drop\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        h = F.relu(self.fc(x))\n",
    "        if self.drop:\n",
    "            h = F.dropout(h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ConvBlock`は`Chain`を継承した小さなネットワークとして定義されています。これは一つの畳み込み層とBatch Normalization層をパラメータありで持っているので、コンストラクタ内でこれらの登録を行っています。`__call__`メソッドでは、これらにデータを渡しつつ、活性化関数ReLUを適用して、さらに`pool_drop`がコンストラクタに`True`で渡されているときはMax PoolingとDropoutという関数を適用するようになっています。\n",
    "\n",
    "Chainerでは、Pythonを使って書いたforward計算のコード自体がネットワークの構造を表します。すなわち、実行時にデータがどのような層をくぐっていったか、ということがネットワークそのものを定義します。これによって、上記のような分岐などを含むネットワークも簡単に書け、柔軟かつシンプルで可読性の高いネットワーク定義が可能になります。これが**Define-by-Run**と呼ばれる特徴です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 大きなネットワークの定義\n",
    "\n",
    "次に、これらの小さなネットワークを構成要素として積み重ねて、大きなネットワークを定義してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepCNN(chainer.ChainList):\n",
    "\n",
    "    def __init__(self, n_output):\n",
    "        super(DeepCNN, self).__init__(\n",
    "            ConvBlock(64),\n",
    "            ConvBlock(64, True),\n",
    "            ConvBlock(128),\n",
    "            ConvBlock(128, True),\n",
    "            ConvBlock(256),\n",
    "            ConvBlock(256),\n",
    "            ConvBlock(256),\n",
    "            ConvBlock(256, True),\n",
    "            LinearBlock(),\n",
    "            LinearBlock(),\n",
    "            L.Linear(None, n_output)\n",
    "        )\n",
    "\n",
    "    def __call__(self, x):\n",
    "        for f in self:\n",
    "            x = f(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここで利用しているのが、`ChainList`というクラスです。このクラスは`Chain`を継承したクラスで、いくつもの`Link`や`Chain`を順次呼び出していくようなネットワークを定義するときに便利です。`ChainList`を継承して定義されるモデルは、親クラスのコンストラクタを呼び出す際に**キーワード引数ではなく普通の引数として**`Link`もしくは`Chain`オブジェクトを渡すことができます。そしてこれらは、`self.children()`メソッドによって**登録した順番に**取り出すことができます。`ChainList`自体もPythonのイテレータとして機能するので、例えば`ChainList`を継承したクラスの中で`for f in self:...`といったことも可能です。\n",
    "\n",
    "この特徴を使うと、forward計算の記述が簡単になります。`self.children()`が返す構成要素のリストから、for文で構成要素を順番に取り出していき、そもそもの入力である`x`に取り出してきた部分ネットワークの計算を適用して、この出力で`x`を置き換えるということを順番に行っていけば、一連の`Link`または`Chain`を、コンストラクタで親クラスに登録した順番と同じ順番で適用していくことができます。そのため、シーケンシャルな部分ネットワークの適用によって表される大きなネットワークを定義するのに重宝します。\n",
    "\n",
    "それでは、学習を回してみます。今回はパラメータ数も多いので、学習を停止するエポック数を100に設定します。また、学習率を0.1から始めて、30エポックごとに10分の1にするように設定してみます。\n",
    "\n",
    "#### TIPS\n",
    "\n",
    "今回は多くの畳込み層を使う大きなネットワークを使うので、Chainerが用意してくれているcuDNNのautotune機能を有効可してみます。やり方は簡単で、以下の二行を事前に実行しておくだけです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chainer.cuda.set_max_workspace_size(512 * 1024 * 1024)\n",
    "chainer.config.autotune = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "それでは、今度こそ学習を開始してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "reset_seed(0)\n",
    "\n",
    "model = train(DeepCNN(10), max_epoch=100, base_lr=0.1, lr_decay=(30, 'epoch'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習が終了しました。ロスカーブと精度のグラフを見てみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='DeepCNN_cifar10_result/loss.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='DeepCNN_cifar10_result/accuracy.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "先程よりも大幅にValidationデータに対する精度が向上したことが分かります。学習率を10分の1に下げるタイミングでロスががくっと減り、精度がガクッと上がっているのが分かります。最終的に、先程60%前後だったValidationデータでの精度が、90%程度まで上がりました。また、テストデータを用いた精度も、およそ90%程度となっています。しかし最新の研究成果では97%以上まで達成されています。さらに精度を上げるには、今回行ったようなネットワークの構造自体の改良ももちろんのこと、学習データを擬似的に増やす操作（Data augmentation）や、複数のモデルの出力を一つの出力に統合する操作（Ensemble）などなど、いろいろな工夫が考えられます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データセットクラスを書いてみよう\n",
    "\n",
    "ここでは、Chainerにすでに用意されているCIFAR10のデータを取得する機能を使って、データセットクラスを自分で書いてみます。Chainerでは、データセットを表すクラスは以下の機能を持っていることが必要とされます。\n",
    "\n",
    "- データセット内のデータ数を返す`__len__`メソッド\n",
    "- 引数として渡される`i`に対応したデータもしくはデータとラベルの組を返す`get_example`メソッド\n",
    "\n",
    "その他のデータセットに必要な機能は、`chainer.dataset.DatasetMixin`クラスを継承することで用意できます。ここでは、`DatasetMixin`クラスを継承し、Data augmentation機能のついたデータセットクラスを作成してみましょう。\n",
    "\n",
    "#### NOTE\n",
    "\n",
    "自前で用意した、もしくはどこからから調達したラベル付き画像データセットを使う場合は、[`LabeledImageDataset`](https://docs.chainer.org/en/stable/reference/generated/chainer.datasets.LabeledImageDataset.html?highlight=LabeledImageDataset)というクラスが非常に便利です。雹災はドキュメントを参照してください：[`LabeledImageDataset`](https://docs.chainer.org/en/stable/reference/generated/chainer.datasets.LabeledImageDataset.html?highlight=LabeledImageDataset)。こちらでも使っています：[Chainerでアニメキャラクターの顔画像を分類する](https://qiita.com/mitmul/items/5502ecdd2f0b444c427f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. CIFAR10データセットクラスを書く"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR10Augmented(chainer.dataset.DatasetMixin):\n",
    "\n",
    "    def __init__(self, split='train', train_ratio=0.9):\n",
    "        train_val, test_data = cifar.get_cifar10()\n",
    "        train_size = int(len(train_val) * train_ratio)\n",
    "        train_data, valid_data = split_dataset_random(train_val, train_size, seed=0)\n",
    "        if split == 'train':\n",
    "            self.data = train_data\n",
    "        elif split == 'valid':\n",
    "            self.data = valid_data\n",
    "        elif split == 'test':\n",
    "            self.data = test_data\n",
    "        else:\n",
    "            raise ValueError(\"'split' argument should be either 'train', 'valid', or 'test'. But {} was given.\".format(split))\n",
    "\n",
    "        self.split = split\n",
    "        self.random_crop = 4\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def get_example(self, i):\n",
    "        x, t = self.data[i]\n",
    "        if self.split == 'train':\n",
    "            x = x.transpose(1, 2, 0)\n",
    "            h, w, _ = x.shape\n",
    "            x_offset = np.random.randint(self.random_crop)\n",
    "            y_offset = np.random.randint(self.random_crop)\n",
    "            x = x[y_offset:y_offset + h - self.random_crop,\n",
    "                  x_offset:x_offset + w - self.random_crop]\n",
    "            if np.random.rand() > 0.5:\n",
    "                x = np.fliplr(x)\n",
    "            x = x.transpose(2, 0, 1)\n",
    "\n",
    "        return x, t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このクラスは、CIFAR10のデータのそれぞれに対し、\n",
    "\n",
    "- 32x32の大きさの中からランダムに28x28の領域をクロップ\n",
    "- 1/2の確率で左右を反転させる\n",
    "\n",
    "という加工を行っています。こういった操作を加えることで擬似的に学習データのバリエーションを増やすと、オーバーフィッティングを抑制することに役に立つということが知られています。これらの操作以外にも、画像の色味を変化させるような変換やランダムな回転、アフィン変換など、さまざまな加工によって学習データ数を擬似的に増やす方法が提案されています。\n",
    "\n",
    "自分でデータの取得部分も書く場合は、コンストラクタに画像フォルダのパスとファイル名に対応したラベルの書かれたテキストファイルへのパスなどを渡してプロパティとして保持しておき、`get_example`メソッド内でそれぞれの画像を読み込んで対応するラベルとともに返す、という風にすれば良いことが分かります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 作成したデータセットクラスを使って学習を行う\n",
    "\n",
    "それではさっそくこの`CIFAR10`クラスを使って学習を行ってみましょう。先程使ったのと同じ大きなネットワークを使うことで、Data augmentationの効果がどの程度あるのかを調べてみましょう。`train`関数も含め、データセットクラス以外は先程とすべて同様です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "reset_seed(0)\n",
    "\n",
    "model = train(DeepCNN(10), max_epoch=100, train_dataset=CIFAR10Augmented(), valid_dataset=CIFAR10Augmented('valid'), test_dataset=CIFAR10Augmented('test'), postfix='augmented_', base_lr=0.1, lr_decay=(30, 'epoch'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "先程のData augmentationなしの場合は90%程度だったテスト精度が、学習データにaugmentationを施すことで92%程度まで向上させられることが分かりました。およそ2%の改善です。\n",
    "\n",
    "ロスと精度のグラフを見てみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='DeepCNN_cifar10_augmented_result/loss.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Image(filename='DeepCNN_cifar10_augmented_result/accuracy.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# もっと簡単にData Augmentationしよう\n",
    "\n",
    "前述のようにデータセット内の各画像についていろいろな変換を行って擬似的にデータを増やすような操作をData Augmentationといいます。上では、オリジナルのデータセットクラスを作る方法を示すために変換の操作も`get_example()`内に書くという実装を行いましたが、実はもっと簡単にいろいろな変換をデータに対して行う方法があります。\n",
    "\n",
    "それは、`TransformDataset`クラスを使う方法です。`TransformDataset`は、元になるデータセットオブジェクトと、そこからサンプルしてきた各データ点に対して行いたい変換を関数の形で与えると、変換済みのデータを返してくれるようなデータセットオブジェクトに加工してくれる便利なクラスです。かんたんな使い方は以下です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chainer.datasets import TransformDataset\n",
    "\n",
    "train_val, test_dataset = cifar.get_cifar10()\n",
    "train_size = int(len(train_val) * 0.9)\n",
    "train_dataset, valid_dataset = split_dataset_random(train_val, train_size, seed=0)\n",
    "\n",
    "\n",
    "# 行いたい変換を関数の形で書く\n",
    "def transform(inputs):\n",
    "    x, t = inputs\n",
    "    x = x.transpose(1, 2, 0)\n",
    "    h, w, _ = x.shape\n",
    "    x_offset = np.random.randint(4)\n",
    "    y_offset = np.random.randint(4)\n",
    "    x = x[y_offset:y_offset + h - 4,\n",
    "          x_offset:x_offset + w - 4]\n",
    "    if np.random.rand() > 0.5:\n",
    "        x = np.fliplr(x)\n",
    "    x = x.transpose(2, 0, 1)\n",
    "    \n",
    "    return x, t\n",
    "\n",
    "\n",
    "# 各データをtransformにくぐらせたものを返すデータセットオブジェクト\n",
    "train_dataset = TransformDataset(train_dataset, transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このようにすると、この新しい`train_dataset`は、上で自分でデータセットクラスごと書いたときと同じような変換を行った上でデータを返してくれるデータセットオブジェクトになります。\n",
    "\n",
    "## ChainerCVでいろいろな変換を簡単に行おう\n",
    "\n",
    "さて、上では画像に対してランダムクロップと、ランダムに左右反転というのをやりました。もっと色々な変換を行いたい場合、上記の`transform`関数に色々な処理を追加していけばよいことになりますが、毎回使いまわすような変換処理をそのたびに書くのは面倒です。何かいいライブラリとか無いのかな、となります。そこで[ChainerCV](http://chainercv.readthedocs.io/en/stable)[[Niitani 2017]](https://arxiv.org/abs/1708.08169)です！今年のACM MultimediaのOpen Source Software CompetitionにWebDNN[[Hidaka 2017]](https://dl.acm.org/citation.cfm?id=3129394)とともに出場していたChainerにComputer Vision向けの便利な機能を色々追加する補助パッケージ的なオープンソース・ソフトウェアです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "pip install chainercv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[ChainerCV](http://chainercv.readthedocs.io/en/stable)には、画像に対する様々な変換があらかじめ用意されています。\n",
    "\n",
    "- [ChainerCVで使える画像変換一覧](http://chainercv.readthedocs.io/en/stable/reference/transforms.html#image)\n",
    "\n",
    "そのため、上でNumPyを使ってごにょごにょ書いていたランダムクロップやランダム左右反転は、`chainercv.transforms`モジュールを使うと、それぞれ以下のように1行で書くことができます：\n",
    "\n",
    "```python\n",
    "x = transforms.random_crop(x, (28, 28))  # ランダムクロップ\n",
    "x = chainercv.transforms.random_flip(x)  # ランダム左右反転\n",
    "```\n",
    "\n",
    "`chainercv.transforms`モジュールを使って、`transform`関数をアップデートしてみましょう。ちなみに、`get_cifar10()`で得られるデータセットでは、デフォルトで画像の画素値の範囲が`[0, 1]`にスケールされています。しかし、`get_cifar10()`に`scale=255.`を渡しておくと、値の範囲をもともとの`[0, 255]`のままにできます。今回`transform`の中で行う処理は、以下の5つです：\n",
    "\n",
    "1. PCA lighting: これは大雑把に言えば、少しだけ色味を変えるような変換です\n",
    "2. Standardization: 訓練用データセット全体からチャンネルごとの画素値の平均・標準偏差を求めて標準化をします\n",
    "3. Random flip: ランダムに画像の左右を反転します\n",
    "4. Random expand: `[1, 1.5]`からランダムに決めた大きさの黒いキャンバスを作り、その中のランダムな位置へ画像を配置します\n",
    "5. Random crop: `(28, 28)`の大きさの領域をランダムにクロップします"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'chainercv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-8020c0072d79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfunctools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mchainercv\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrain_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcifar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_cifar10\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m255.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrain_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_val\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'chainercv'"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "from chainercv import transforms\n",
    "\n",
    "train_val, test_dataset = cifar.get_cifar10(scale=255.)\n",
    "train_size = int(len(train_val) * 0.9)\n",
    "train_dataset, valid_dataset = split_dataset_random(train_val, train_size, seed=0)\n",
    "\n",
    "mean = np.mean([x for x, _ in train_dataset], axis=(0, 2, 3))\n",
    "std = np.std([x for x, _ in train_dataset], axis=(0, 2, 3))\n",
    "\n",
    "\n",
    "def transform(inputs, train=True):\n",
    "    img, label = inputs\n",
    "    img = img.copy()\n",
    "    \n",
    "    # Color augmentation\n",
    "    if train:\n",
    "        img = transforms.pca_lighting(img, 76.5)\n",
    "        \n",
    "    # Standardization\n",
    "    img -= mean[:, None, None]\n",
    "    img /= std[:, None, None]\n",
    "    \n",
    "    # Random flip & crop\n",
    "    if train:\n",
    "        img = transforms.random_flip(img, x_random=True)\n",
    "        img = transforms.random_expand(img, max_ratio=1.5)\n",
    "        img = transforms.random_crop(img, (28, 28))\n",
    "        \n",
    "    return img, label\n",
    "\n",
    "train_dataset = TransformDataset(train_dataset, partial(transform, train=True))\n",
    "valid_dataset = TransformDataset(valid_dataset, partial(transform, train=False))\n",
    "test_dataset = TransformDataset(test_dataset, partial(transform, train=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ちなみに、`pca_lighting`は、大雑把にいうと色味を微妙に変えた画像を作ってくれる関数です。\n",
    "\n",
    "では、standardizationとChainerCVによるPCA Lightingを追加した`TransformDataset`を使って学習をしてみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "reset_seed(0)\n",
    "\n",
    "model = train(DeepCNN(10), max_epoch=100, train_dataset=train_dataset, valid_dataset=valid_dataset, test_dataset=test_dataset, postfix='augmented2_', base_lr=0.1, lr_decay=(30, 'epoch'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "わずかに精度が向上しました。他にもネットワークにResNetと呼ばれる有名なアーキテクチャを採用するなど、簡単に試せる改善方法がいくつかあります。ぜひご自分で色々と試してみてください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# おわりに\n",
    "\n",
    "**Chainerの開発にコミットしてくれる方を歓迎します！**Chainerはオープンソースソフトウェアですので、皆さんが自身で欲しい機能などを提案し、Pull requestを送ることで進化していきます。興味のある方は、こちらの[Contoribution Guide](http://docs.chainer.org/en/latest/contribution.html)をお読みになった後、ぜひIssueを立てたりPRを送ったりしてみてください。お待ちしております。\n",
    "\n",
    "chainer/chainer\n",
    "[https://github.com/chainer/chainer](https://github.com/pfnet/chainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 参考文献\n",
    "\n",
    "[Tokui 2015] Tokui, S., Oono, K., Hido, S. and Clayton, J., Chainer: a Next-Generation Open Source Framework for Deep Learning, Proceedings of Workshop on Machine Learning Systems(LearningSys) in The Twenty-ninth Annual Conference on Neural Information Processing Systems (NIPS), (2015)\n",
    "\n",
    "[Niitani 2017] Yusuke Niitani, Toru Ogawa, Shunta Saito, Masaki Saito, \"ChainerCV: a Library for Deep Learning in Computer Vision\", ACM Multimedia (ACMMM), Open Source Software Competition, 2017\n",
    "\n",
    "[Hidaka 2017] Masatoshi Hidaka, Yuichiro Kikura, Yoshitaka Ushiku, Tatsuya Harada. WebDNN: Fastest DNN Execution Framework on Web Browser. ACM International Conference on Multimedia (ACMMM), Open Source Software Competition, pp.1213-1216, 2017.\n",
    "\n",
    "#### 脚注\n",
    "\n",
    "[^cudnnenv]: `cudnnenv`は好きなバージョンのcuDNNを簡単に持ってこれるツールです。`pip install cudnnenv`でインストールし、[こちら](https://github.com/unnonouno/cudnnenv#install)にあるインストラクションに従えば、簡単にいろいろなCUDAバージョン向けの様々なバージョンのcuDNNをインストールすることができます。使い方も[こちら](https://github.com/unnonouno/cudnnenv)のREADMEに書いてあるとおり、単純明快です。\n",
    "[^NN]: 学習データに対する予測精度は、もし学習データから抜き出されたあるデータをクエリとし、それが含まれている学習データセットから検索して発見することが必ずできるならば、そのデータについているラベルを答えることで、100%になってしまいます。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
